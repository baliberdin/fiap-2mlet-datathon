{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d6e280",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "import pandas as pd\n",
    "#import data_transform_utilities.flatten as flatten\n",
    "#from data_transform_utilities.text_parsers import  clean_str, extract_json, json_str_to_array, normalize_and_tokenize_text\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "import re\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import ArrayType, StringType\n",
    "\n",
    "import pysolr\n",
    "from sqlalchemy import create_engine\n",
    "import json\n",
    "import requests\n",
    "\n",
    "from sqlalchemy import create_engine, update, Table, MetaData\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import Distance, VectorParams, PointStruct\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForSequenceClassification\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1975f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_conf = SparkConf()\n",
    "spark_conf.set(\"spark.cores\", \"12\")\n",
    "spark_conf.set(\"spark.driver.cores\", \"12\")\n",
    "spark_conf.set(\"spark.speculation\", False)\n",
    "spark_conf.set(\"spark.jars.packages\", \"com.mysql:mysql-connector-j:9.2.0\")\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder.master(\"local\") \\\n",
    "    .appName(\"Decision data overview\") \\\n",
    "    .config(conf=spark_conf) \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a26c709",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(\"mysql+pymysql://decision:1234@localhost/decision?charset=utf8\")\n",
    "days_to_read = 1800"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a4d2b0",
   "metadata": {},
   "source": [
    "## Carrega os dados de vagas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977cfac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.read.jdbc(\n",
    "    url=\"jdbc:mysql://decision:1234@localhost:3306/decision?charset=utf8\",\n",
    "    table=f\"(SELECT * FROM vacancies WHERE requested_date > DATE_ADD(current_date(), INTERVAL -{days_to_read} DAY)) AS t\",\n",
    "    properties={\"driver\": \"com.mysql.cj.jdbc.Driver\"}\n",
    ").createOrReplaceTempView(\"vacancies\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5c11b1",
   "metadata": {},
   "source": [
    "# Carrega os dados de candidatos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae5ef8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.read.jdbc(\n",
    "    url=\"jdbc:mysql://decision:1234@localhost:3306/decision?charset=utf8\",\n",
    "    table=f\"(SELECT * FROM applicants WHERE created_at > DATE_ADD(current_date(), INTERVAL -{days_to_read} DAY)) AS t\",\n",
    "    properties={\"driver\": \"com.mysql.cj.jdbc.Driver\"}\n",
    ").createOrReplaceTempView(\"applicants\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab36cb3",
   "metadata": {},
   "source": [
    "# Carrega o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7559fef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_version = \"0.0.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a18a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega modelo e tokenizer\n",
    "model_version = \"0.0.1\"\n",
    "#model_name = \"neuralmind/bert-base-portuguese-cased\"\n",
    "model_name = \"../trained_model_bert_20250508\"\n",
    "tokenizer_name = \"../tokenizer_model_bert_20250508\" \n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d89080",
   "metadata": {},
   "source": [
    "# Novo modelo com Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3098e338",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "import mlflow\n",
    "import mlflow.sentence_transformers\n",
    "from sentence_transformers import SentenceTransformer, InputExample, models, losses, evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9686a16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'applicant_job_similarity'\n",
    "MLFLOW_TRACKING_URI = 'http://192.168.101.186:5000'\n",
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9db8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mlflow.sentence_transformers.load_model(\"models:/applicant_job_similarity/21\")\n",
    "#model = models.Transformer(\"neuralmind/bert-base-portuguese-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ed6b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4aa340c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = SentenceTransformer(\"./modelo_finetuned_afinidade\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a3fe54",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_vaga = model.encode(\"Vaga: Desenvolvedor Pyhton\", normalize_embeddings=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6491531f",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_vaga"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9027e46",
   "metadata": {},
   "source": [
    "# Função de embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a096013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para gerar embedding médio da sequência\n",
    "def get_embedding(text, model, tokenizer):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    # Média dos embeddings dos tokens (ignorando padding)\n",
    "    attention_mask = inputs[\"attention_mask\"]\n",
    "    embeddings = outputs.last_hidden_state\n",
    "    mask_expanded = attention_mask.unsqueeze(-1).expand(embeddings.size()).float()\n",
    "    sum_embeddings = torch.sum(embeddings * mask_expanded, 1)\n",
    "    sum_mask = torch.clamp(mask_expanded.sum(1), min=1e-9)\n",
    "    mean_embedding = sum_embeddings / sum_mask\n",
    "    return mean_embedding.squeeze().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64cdc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding2(text, model):\n",
    "    return model.encode(text, normalize_embeddings=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb67c988",
   "metadata": {},
   "source": [
    "# Cria client do banco de Vetores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e5a172",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = QdrantClient(host=\"localhost\", port=6333)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7e577a",
   "metadata": {},
   "source": [
    "# Cria as coleções no Qdrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e998d105",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not client.collection_exists(collection_name=\"applicants\"):\n",
    "    client.create_collection(\n",
    "        collection_name=\"applicants\",\n",
    "        vectors_config=VectorParams(size=768, distance=Distance.COSINE),\n",
    "    )\n",
    "\n",
    "if not client.collection_exists(collection_name=\"vacancies\"):\n",
    "    client.create_collection(\n",
    "        collection_name=\"vacancies\",\n",
    "        vectors_config=VectorParams(size=768, distance=Distance.COSINE),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c753e238",
   "metadata": {},
   "source": [
    "# Inicia a inserção no banco de Vetores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa53287",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_into_db(c, collection_name):\n",
    "    client.upsert(\n",
    "        collection_name=collection_name,\n",
    "        points=[\n",
    "            PointStruct(\n",
    "                id=c[\"id\"],\n",
    "                vector=c[\"embeddings\"],\n",
    "                payload={\"description\": c[\"description\"]}\n",
    "            )\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41356281",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_batch(batch, collection_name, model):\n",
    "    result = [insert_into_db(\n",
    "        {\"id\": v.id, \"description\": v.description, \n",
    "        #\"embeddings\": get_embedding(v.description, model, tokenizer), \n",
    "        \"embeddings\": get_embedding2(v.description, model), \n",
    "        \"model_version\": v.model_version}, collection_name) for v in batch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd462643",
   "metadata": {},
   "outputs": [],
   "source": [
    "vacancies = spark.sql(f\"\"\"\n",
    "    SELECT\n",
    "        *\n",
    "    FROM\n",
    "        (SELECT\n",
    "            id,\n",
    "            CONCAT(\n",
    "                COALESCE(main_activities, ''), '\\n', \n",
    "                COALESCE(technical_and_behavioral_skills, ''), '\\n',\n",
    "                COALESCE(behavioral_skills, ''), '\\n',\n",
    "                'país: ', COALESCE(country, ''), '\\n',\n",
    "                'estado: ', COALESCE(state, ''), '\\n',\n",
    "                'cidade: ', COALESCE(city, ''), '\\n'\n",
    "            ) AS description,\n",
    "            CURRENT_DATE() AS dt,\n",
    "            '{model_version}' AS model_version\n",
    "        FROM \n",
    "            vacancies v\n",
    "        ORDER BY id DESC\n",
    "        ) AS t\n",
    "    WHERE LENGTH(TRIM(REGEXP_REPLACE(description, '\\n', ''))) > 0\n",
    "    -- LIMIT 500\n",
    "\"\"\").collect()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48800e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_batch(vacancies, \"vacancies\", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51874133",
   "metadata": {},
   "outputs": [],
   "source": [
    "applicants = spark.sql(f\"\"\"\n",
    "    SELECT\n",
    "        *\n",
    "    FROM\n",
    "        (SELECT\n",
    "            id,\n",
    "            CONCAT(\n",
    "                COALESCE(technical_knowledge, ''), '\\n',\n",
    "                COALESCE(cv_pt, ''), '\\n',\n",
    "                'Endereço: ', COALESCE(location, '')\n",
    "            ) AS description,\n",
    "            CURRENT_DATE() AS dt,\n",
    "            '{model_version}' AS model_version\n",
    "        FROM \n",
    "            applicants a\n",
    "        ORDER BY id DESC\n",
    "        ) AS t\n",
    "    WHERE LENGTH(TRIM(REGEXP_REPLACE(description, '\\n', ''))) > 0\n",
    "    -- LIMIT 500\n",
    "\n",
    "\"\"\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2806c361",
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_batch(applicants, \"applicants\", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a663b120",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client.models import ExtendedPointId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67547fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ponto_a = client.retrieve(\n",
    "    collection_name=\"vacancies\",\n",
    "    ids=[14153],\n",
    "    with_vectors=True\n",
    ")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50a43a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ponto_a.payload[\"description\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570c7040",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados = client.query_points(\n",
    "    collection_name=\"applicants\",\n",
    "    query=ponto_a.vector, \n",
    "    limit=3\n",
    ")\n",
    "\n",
    "# Exibir resultados\n",
    "for r in resultados.points:\n",
    "    print(r.payload[\"description\"])\n",
    "    print(\"----------------------------------------------------------\\n\")\n",
    "    #print(f\"ID: {r.id} | Score: {r.score:.4f} | Descrição: {r.payload['descricao']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641ea9ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
