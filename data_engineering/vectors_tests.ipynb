{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d6e280",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "import pandas as pd\n",
    "#import data_transform_utilities.flatten as flatten\n",
    "#from data_transform_utilities.text_parsers import  clean_str, extract_json, json_str_to_array, normalize_and_tokenize_text\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "import re\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import ArrayType, StringType\n",
    "\n",
    "import pysolr\n",
    "from sqlalchemy import create_engine\n",
    "import json\n",
    "import requests\n",
    "\n",
    "from sqlalchemy import create_engine, update, Table, MetaData\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import Distance, VectorParams, PointStruct, MultiVectorConfig, MultiVectorComparator, NamedVectorStruct, NamedVector\n",
    "\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForSequenceClassification, models\n",
    "import numpy as np\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "import mlflow\n",
    "import mlflow.sentence_transformers\n",
    "from sentence_transformers import SentenceTransformer, InputExample, models, losses, evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1975f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_conf = SparkConf()\n",
    "spark_conf.set(\"spark.cores\", \"12\")\n",
    "spark_conf.set(\"spark.driver.cores\", \"12\")\n",
    "spark_conf.set(\"spark.speculation\", False)\n",
    "spark_conf.set(\"spark.jars.packages\", \"com.mysql:mysql-connector-j:9.2.0\")\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder.master(\"local\") \\\n",
    "    .appName(\"Decision data overview\") \\\n",
    "    .config(conf=spark_conf) \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a26c709",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(\"mysql+pymysql://decision:1234@localhost/decision?charset=utf8\")\n",
    "days_to_read = 3000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a4d2b0",
   "metadata": {},
   "source": [
    "## Carrega os dados de vagas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977cfac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.read.jdbc(\n",
    "    url=\"jdbc:mysql://decision:1234@localhost:3306/decision?charset=utf8\",\n",
    "    table=f\"(SELECT * FROM vacancies WHERE requested_date > DATE_ADD(current_date(), INTERVAL -{days_to_read} DAY)) AS t\",\n",
    "    properties={\"driver\": \"com.mysql.cj.jdbc.Driver\"}\n",
    ").createOrReplaceTempView(\"vacancies\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5c11b1",
   "metadata": {},
   "source": [
    "# Carrega os dados de candidatos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae5ef8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.read.jdbc(\n",
    "    url=\"jdbc:mysql://decision:1234@localhost:3306/decision?charset=utf8\",\n",
    "    table=f\"(SELECT * FROM applicants WHERE created_at > DATE_ADD(current_date(), INTERVAL -{days_to_read} DAY)) AS t\",\n",
    "    properties={\"driver\": \"com.mysql.cj.jdbc.Driver\"}\n",
    ").createOrReplaceTempView(\"applicants\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0354a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.read.jdbc(\n",
    "    url=\"jdbc:mysql://decision:1234@localhost:3306/decision?charset=utf8\",\n",
    "    table=f\"(SELECT * FROM vacancies_applicants WHERE last_update > DATE_ADD(current_date(), INTERVAL -{days_to_read} DAY)) AS t\",\n",
    "    properties={\"driver\": \"com.mysql.cj.jdbc.Driver\"}\n",
    ").createOrReplaceTempView(\"vacancies_applicants\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab36cb3",
   "metadata": {},
   "source": [
    "# Carrega o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7559fef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_version = \"0.0.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a18a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega modelo e tokenizer\n",
    "#model_version = \"0.0.1\"\n",
    "#model_name = \"neuralmind/bert-base-portuguese-cased\"\n",
    "##model_name = \"../trained_model_bert_20250508\"\n",
    "#tokenizer_name = model_name #\"../tokenizer_model_bert_20250508\" \n",
    "#tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "#model = AutoModel.from_pretrained(model_name)\n",
    "#model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef82462c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load the transformer model\n",
    "word_embedding_model = models.Transformer('neuralmind/bert-base-portuguese-cased', max_seq_length=512)\n",
    "\n",
    "# 2. Add a pooling layer (mean pooling is common)\n",
    "pooling_model = models.Pooling(\n",
    "    word_embedding_model.get_word_embedding_dimension(),\n",
    "    pooling_mode_mean_tokens=True,\n",
    "    pooling_mode_cls_token=False,\n",
    "    pooling_mode_max_tokens=False\n",
    ")\n",
    "\n",
    "# 3. Build the SentenceTransformer model\n",
    "model = SentenceTransformer(modules=[word_embedding_model, pooling_model])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d89080",
   "metadata": {},
   "source": [
    "# Novo modelo com Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9686a16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'applicant_job_similarity'\n",
    "MLFLOW_TRACKING_URI = 'http://192.168.101.186:5000'\n",
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9db8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mlflow.sentence_transformers.load_model(\"models:/applicant_job_similarity/21\")\n",
    "#model = models.Transformer(\"neuralmind/bert-base-portuguese-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a3fe54",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_vaga = model.encode(\"Vaga: Desenvolvedor Pyhton\", normalize_embeddings=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9027e46",
   "metadata": {},
   "source": [
    "# Função de embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a096013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para gerar embedding médio da sequência\n",
    "#def get_embedding(text, model, tokenizer):\n",
    "#    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "#    with torch.no_grad():\n",
    "#        outputs = model(**inputs)\n",
    "#    # Média dos embeddings dos tokens (ignorando padding)\n",
    "#    attention_mask = inputs[\"attention_mask\"]\n",
    "#    embeddings = outputs.last_hidden_state\n",
    "#    mask_expanded = attention_mask.unsqueeze(-1).expand(embeddings.size()).float()\n",
    "#    sum_embeddings = torch.sum(embeddings * mask_expanded, 1)\n",
    "#    sum_mask = torch.clamp(mask_expanded.sum(1), min=1e-9)\n",
    "#    mean_embedding = sum_embeddings / sum_mask\n",
    "#    return mean_embedding.squeeze().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64cdc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text, model):\n",
    "    return model.encode(text, normalize_embeddings=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb67c988",
   "metadata": {},
   "source": [
    "# Cria client do banco de Vetores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e5a172",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = QdrantClient(host=\"localhost\", port=6333)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7e577a",
   "metadata": {},
   "source": [
    "# Cria as coleções no Qdrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e998d105",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not client.collection_exists(collection_name=\"applicants\"):\n",
    "    client.create_collection(\n",
    "        collection_name=\"applicants\",\n",
    "        vectors_config={\n",
    "            \"title\": VectorParams(size=768, distance=Distance.COSINE),\n",
    "            \"description\": VectorParams(size=768, distance=Distance.COSINE),\n",
    "            \"location\": VectorParams(size=768, distance=Distance.COSINE),\n",
    "        }\n",
    "    )\n",
    "\n",
    "if not client.collection_exists(collection_name=\"vacancies\"):\n",
    "    client.create_collection(\n",
    "        collection_name=\"vacancies\",\n",
    "        vectors_config={\n",
    "            \"title\": VectorParams(size=768, distance=Distance.COSINE),\n",
    "            \"description\": VectorParams(size=768, distance=Distance.COSINE),\n",
    "            \"location\": VectorParams(size=768, distance=Distance.COSINE),\n",
    "        },\n",
    "    )\n",
    "    \n",
    "if not client.collection_exists(collection_name=\"job_titles\"):\n",
    "    client.create_collection(\n",
    "        collection_name=\"job_titles\",\n",
    "        vectors_config= VectorParams(size=768, distance=Distance.COSINE),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c753e238",
   "metadata": {},
   "source": [
    "# Inicia a inserção no banco de Vetores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa53287",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_into_db(c, collection_name):\n",
    "    client.upsert(\n",
    "        collection_name=collection_name,\n",
    "        points=[\n",
    "            PointStruct(\n",
    "                id=c[\"id\"],\n",
    "                vector={\n",
    "                    \"title\":c[\"title_embeddings\"],\n",
    "                    \"description\": c[\"description_embeddings\"],\n",
    "                    \"location\": c[\"location_embeddings\"],\n",
    "                },\n",
    "                payload={\"title\":c[\"title\"], \"description\": c[\"description\"], \"location\": c[\"location\"]}\n",
    "            )\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41356281",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_batch(batch, collection_name, model):\n",
    "    [insert_into_db(\n",
    "        {\"id\": v.id, \"title\":v.title,\"description\": v.description, \"location\": v.location, \n",
    "        \"title_embeddings\": get_embedding(v.title, model), \n",
    "        \"description_embeddings\": get_embedding(v.description, model), \n",
    "        \"location_embeddings\": get_embedding(v.location, model),\n",
    "        \"model_version\": v.model_version}, collection_name) for v in batch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dd462643",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "vacancies = spark.sql(f\"\"\"\n",
    "    SELECT\n",
    "        *\n",
    "    FROM\n",
    "        (SELECT\n",
    "            id,\n",
    "            LOWER(\n",
    "                CONCAT(\n",
    "                    COALESCE(main_activities, ''), '\\n', \n",
    "                    COALESCE(technical_and_behavioral_skills, ''), '\\n',\n",
    "                    COALESCE(behavioral_skills, ''), '\\n'\n",
    "                )\n",
    "            ) AS description,\n",
    "            \n",
    "            TRIM(REGEXP_REPLACE(LOWER(title), '[0-9]+','')) as title,\n",
    "            \n",
    "            TRIM(LOWER(CONCAT(\n",
    "                'país: ', COALESCE(country, ''), '\\n',\n",
    "                'estado: ', COALESCE(state, ''), '\\n',\n",
    "                'cidade: ', COALESCE(city, ''), '\\n'\n",
    "            ))) AS location,\n",
    "            \n",
    "            CURRENT_DATE() AS dt,\n",
    "            '{model_version}' AS model_version\n",
    "        FROM \n",
    "            vacancies v\n",
    "        WHERE \n",
    "            v.id IN (SELECT vacancy_id FROM vacancies_applicants group by 1)\n",
    "        ORDER BY id DESC\n",
    "        ) AS t\n",
    "    WHERE \n",
    "        LENGTH(TRIM(REGEXP_REPLACE(title, '\\n', ''))) > 0\n",
    "        AND LENGTH(TRIM(REGEXP_REPLACE(description, '\\n', ''))) > 0\n",
    "        AND LENGTH(TRIM(REGEXP_REPLACE(location, '\\n', ''))) > 0\n",
    "    -- LIMIT 500\n",
    "\"\"\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48800e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_batch(vacancies, \"vacancies\", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "51874133",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "applicants = spark.sql(f\"\"\"\n",
    "    SELECT\n",
    "        *\n",
    "    FROM\n",
    "        (SELECT\n",
    "            id,\n",
    "            LOWER(CONCAT(\n",
    "                COALESCE(technical_knowledge, ''), '\\n',\n",
    "                COALESCE(cv_pt, ''), '\\n',\n",
    "                'Endereço: ', COALESCE(location, '')\n",
    "            )) AS description,\n",
    "            TRIM(REGEXP_REPLACE(LOWER(professional_title), '[0-9]+','')) as title,\n",
    "            CURRENT_DATE() AS dt,\n",
    "            '{model_version}' AS model_version,\n",
    "            LOWER(TRIM(location)) AS location\n",
    "        FROM \n",
    "            applicants a\n",
    "        WHERE \n",
    "            a.id IN (SELECT applicant_id FROM vacancies_applicants group by 1)\n",
    "        ORDER BY id\n",
    "        ) AS t\n",
    "    WHERE \n",
    "        LENGTH(TRIM(REGEXP_REPLACE(description, '\\n', ''))) > 0\n",
    "        AND LENGTH(TRIM(REGEXP_REPLACE(title, '\\n', ''))) > 0\n",
    "        AND LENGTH(TRIM(REGEXP_REPLACE(location, '\\n', ''))) > 0\n",
    "\"\"\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2806c361",
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_batch(applicants, \"applicants\", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a6c150",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_titles = spark.sql(f\"\"\"\n",
    "    SELECT\n",
    "        *\n",
    "    FROM\n",
    "        (SELECT\n",
    "            id,\n",
    "            TRIM(REGEXP_REPLACE(LOWER(professional_title), '[0-9]+','')) as description,\n",
    "            CURRENT_DATE() AS dt,\n",
    "            '{model_version}' AS model_version\n",
    "        FROM\n",
    "            applicants\n",
    "        order by id\n",
    "        ) AS t\n",
    "    WHERE\n",
    "        LENGTH(description) > 0\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598e904f",
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_batch(job_titles.collect(), \"job_titles\", model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bf12ed",
   "metadata": {},
   "source": [
    "# Buscas no Qdrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a663b120",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client.models import ExtendedPointId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3ab0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "point = client.retrieve(collection_name=\"applicants\", ids=[47079], with_vectors=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbb969d",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_name = \"applicants\"\n",
    "weights = {\n",
    "    \"title\": 0.5,\n",
    "    \"description\": 0.3,\n",
    "    \"location\": 0.2\n",
    "}\n",
    "\n",
    "# Recupera os vetores do ponto base\n",
    "query_vectors = point.vector\n",
    "\n",
    "# Realiza buscas separadas e acumula os scores\n",
    "scores = {}\n",
    "\n",
    "for field, weight in weights.items():\n",
    "    results = client.search(\n",
    "        collection_name=collection_name,\n",
    "        query_vector=(field, query_vectors[field]),\n",
    "        limit=10\n",
    "    )\n",
    "    for r in results:\n",
    "        if r.id not in scores:\n",
    "            scores[r.id] = 0\n",
    "        scores[r.id] += r.score * weight\n",
    "\n",
    "# Ordena os resultados combinados\n",
    "sorted_results = sorted(scores.items(), key=lambda x: x[1], reverse=True )\n",
    "\n",
    "#print(\"Resultados combinados:\")\n",
    "#for point_id, score in sorted_results:\n",
    "#    print(f\"ID: {point_id}, Score: {score}, {}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c6708e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67547fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ponto_a = client.retrieve(\n",
    "    collection_name=\"applicants\",\n",
    "    ids=[47024],\n",
    "    with_vectors=True\n",
    ")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50a43a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ponto_a.payload[\"description\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570c7040",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados = client.query_points(\n",
    "    collection_name=\"applicants\",\n",
    "    query=ponto_a.vector, \n",
    "    limit=3\n",
    ")\n",
    "\n",
    "# Exibir resultados\n",
    "for r in resultados.points:\n",
    "    print(r.payload[\"description\"])\n",
    "    print(\"----------------------------------------------------------\\n\")\n",
    "    #print(f\"ID: {r.id} | Score: {r.score:.4f} | Descrição: {r.payload['descricao']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdfa254",
   "metadata": {},
   "outputs": [],
   "source": [
    "ponto_a.vector[\"title\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95c91d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client.http.models import QueryRequest, SearchRequest, WithPayloadInterface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a1940b",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_query = SearchRequest(\n",
    "    vector=ponto_a.vector[\"title\"],\n",
    "    limit=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab66d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_requests = [\n",
    "    SearchRequest(\n",
    "        vector_name=\"title\",\n",
    "        vector=\"title\",\n",
    "        query_vector=ponto_a.vector[\"title\"],\n",
    "        limit=10,\n",
    "    ),\n",
    "    SearchRequest(\n",
    "        vector_name=\"description\",\n",
    "        vector=\"title\",\n",
    "        query_vector=ponto_a.vector[\"description\"],\n",
    "        limit=10,\n",
    "    ),\n",
    "    SearchRequest(\n",
    "        vector_name=\"location\",\n",
    "        vector=\"title\",\n",
    "        query_vector=ponto_a.vector[\"location\"],\n",
    "        limit=10,\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641ea9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Combine as sub-buscas utilizando o método DBSF\n",
    "query_request = QueryRequest(\n",
    "    searches=search_requests,\n",
    "    with_payload=WithPayloadInterface(enable=True),\n",
    "    limit=10,\n",
    "    score_aggregation=\"dbsf\"  # ou \"rrf\" para Reciprocal Rank Fusion\n",
    ")\n",
    "\n",
    "# Execute a consulta\n",
    "results = client.query(collection_name=\"candidatos\", query_request=query_request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880c7382",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.search"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
