{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd63143c",
   "metadata": {},
   "source": [
    "# Notebook para c치lculo do NDCG sobre o score gerado pelo modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4dafb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import ndcg_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "import pandas as pd\n",
    "\n",
    "from data_transform_utilities.text_parsers import clean_str\n",
    "from data_transform_utilities.score import generate_score_from_status\n",
    "\n",
    "import os\n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7671cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_conf = SparkConf()\n",
    "spark_conf.set(\"spark.cores\", \"12\")\n",
    "spark_conf.set(\"spark.driver.cores\", \"12\")\n",
    "spark_conf.set(\"spark.speculation\", False)\n",
    "spark_conf.set(\"spark.jars.packages\", \"com.mysql:mysql-connector-j:9.2.0\")\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder.master(\"local\") \\\n",
    "    .appName(\"Decision data overview\") \\\n",
    "    .config(conf=spark_conf) \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78693c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.udf.register(\"generate_score_from_status\", generate_score_from_status)\n",
    "spark.udf.register(\"clean_str\", clean_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e2c48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(\"mysql+pymysql://decision:1234@localhost/decision?charset=utf8\")\n",
    "days_to_read = 3000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d892445d",
   "metadata": {},
   "source": [
    "## Carrega os dados de vagas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c125370e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.read.jdbc(\n",
    "    url=\"jdbc:mysql://decision:1234@localhost:3306/decision?charset=utf8\",\n",
    "    table=f\"(SELECT * FROM vacancies WHERE requested_date > DATE_ADD(current_date(), INTERVAL -{days_to_read} DAY)) AS t\",\n",
    "    properties={\"driver\": \"com.mysql.cj.jdbc.Driver\"}\n",
    ").createOrReplaceTempView(\"vacancies\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73bc6b48",
   "metadata": {},
   "source": [
    "# Carrega os dados de candidatos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67b549d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.read.jdbc(\n",
    "    url=\"jdbc:mysql://decision:1234@localhost:3306/decision?charset=utf8\",\n",
    "    table=f\"(SELECT * FROM applicants WHERE created_at > DATE_ADD(current_date(), INTERVAL -{days_to_read} DAY)) AS t\",\n",
    "    properties={\"driver\": \"com.mysql.cj.jdbc.Driver\"}\n",
    ").createOrReplaceTempView(\"applicants\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fef982",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.read.jdbc(\n",
    "    url=\"jdbc:mysql://decision:1234@localhost:3306/decision?charset=utf8\",\n",
    "    table=f\"(SELECT * FROM vacancies_applicants WHERE last_update > DATE_ADD(current_date(), INTERVAL -{days_to_read} DAY)) AS t\",\n",
    "    properties={\"driver\": \"com.mysql.cj.jdbc.Driver\"}\n",
    ").createOrReplaceTempView(\"vacancies_applicants\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf664e6",
   "metadata": {},
   "source": [
    "# Carrega os dados (hist칩rico recente) para montar o dataset para o NDCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01658d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(f\"\"\"\n",
    "    SELECT\n",
    "        va.vacancy_id,\n",
    "        va.applicant_id,\n",
    "        LOWER(TRIM(clean_str(v.title))) as vacancy_title,\n",
    "        LOWER(COALESCE(v.country, '')) AS country,\n",
    "        LOWER(COALESCE(v.city, '')) AS city,\n",
    "        LOWER(COALESCE(v.state, '')) AS state,\n",
    "        LOWER(COALESCE(v.main_activities, '')) AS main_activities,\n",
    "        LOWER(COALESCE(v.behavioral_skills, '')) AS behavioral_skills,\n",
    "        LOWER(COALESCE(v.technical_and_behavioral_skills, '')) AS technical_and_behavioral_skills,\n",
    "        LOWER(COALESCE(a.location, '')) AS applicant_location,\n",
    "        LOWER(COALESCE(a.professional_title, '')) AS professional_title,\n",
    "        LOWER(COALESCE(a.technical_knowledge, '')) AS technical_knowledge,\n",
    "        LOWER(COALESCE(a.cv_pt,'')) AS cv_pt,\n",
    "        LOWER(COALESCE(a.area_of_expertise,'')) AS area_of_expertise,\n",
    "        generate_score_from_status(status) AS artificial_score\n",
    "    FROM\n",
    "        vacancies_applicants va \n",
    "        LEFT JOIN vacancies v ON v.id = va.vacancy_id \n",
    "        LEFT JOIN applicants a ON a.id = va.applicant_id\n",
    "    WHERE\n",
    "        va.vacancy_id IN\n",
    "            (SELECT\n",
    "                va.vacancy_id\n",
    "            FROM\n",
    "                vacancies_applicants va\n",
    "            GROUP BY 1\n",
    "            HAVING COUNT(DISTINCT va.status) >= 5)          \n",
    "\"\"\").createOrReplaceTempView(\"tmp_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72aaa87",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(f\"\"\"\n",
    "    SELECT\n",
    "        *\n",
    "    FROM\n",
    "        (SELECT\n",
    "            vacancy_id,\n",
    "            CLEAN_STR(\n",
    "                if(main_activities = technical_and_behavioral_skills,\n",
    "                main_activities\n",
    "                ,\n",
    "                CONCAT(\n",
    "                    main_activities, '\\n', \n",
    "                    technical_and_behavioral_skills, '\\n',\n",
    "                    behavioral_skills\n",
    "                )\n",
    "            )) AS vacancy_description,\n",
    "            \n",
    "            vacancy_title,\n",
    "            CONCAT( state, ', ', city) AS vacancy_location,\n",
    "            \n",
    "            applicant_id,\n",
    "            CLEAN_STR(professional_title) AS applicant_title,\n",
    "            TRIM(CLEAN_STR(CONCAT(technical_knowledge, '\\n', cv_pt, '\\n', area_of_expertise))) AS applicant_description,\n",
    "            applicant_location,\n",
    "            artificial_score\n",
    "        FROM \n",
    "            tmp_data v\n",
    "        ) AS t\n",
    "    WHERE\n",
    "        LENGTH(vacancy_title) > 0\n",
    "        AND LENGTH(vacancy_description) > 150\n",
    "        AND LENGTH(vacancy_location) > 0\n",
    "        AND LENGTH(applicant_title) > 0\n",
    "        AND LENGTH(applicant_description) > 150\n",
    "        AND LENGTH(applicant_location) > 0\n",
    "    \n",
    "\"\"\").createOrReplaceTempView(\"tmp_results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338cf6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = spark.sql(f\"\"\"\n",
    "    SELECT\n",
    "        *\n",
    "    FROM\n",
    "        (SELECT \n",
    "            *,\n",
    "            SUM(1) OVER (PARTITION BY vacancy_id) AS items \n",
    "        FROM \n",
    "            tmp_results \n",
    "        ORDER BY \n",
    "            vacancy_id \n",
    "        ) AS t\n",
    "    WHERE\n",
    "        items >= 5\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed354fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = results.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad74194",
   "metadata": {},
   "source": [
    "# Carrega o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a27d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'applicant_job_similarity'\n",
    "MLFLOW_TRACKING_URI = 'http://192.168.101.186:5000'\n",
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "model_version = os.environ[\"MODEL_VERSION\"] if \"MODEL_VERSION\" in os.environ else 27\n",
    "model = mlflow.sentence_transformers.load_model(f\"models:/applicant_job_similarity/{model_version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389a6bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text, model):\n",
    "    return model.encode(text, normalize_embeddings=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5a2798",
   "metadata": {},
   "source": [
    "# Calcula o score (Cosine Similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed24e3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, doc in dataset.iterrows():\n",
    "    # Embeddings da Vaga\n",
    "    query_title = [get_embedding(doc.vacancy_title, model)]\n",
    "    query_description = [get_embedding(doc.vacancy_description, model)]\n",
    "    query_location = [get_embedding(doc.vacancy_location, model)]\n",
    "\n",
    "    # Embeddings do Candidato\n",
    "    title = get_embedding(doc.applicant_title, model)\n",
    "    description = get_embedding(doc.applicant_description, model)\n",
    "    location = get_embedding(doc.applicant_location, model)\n",
    "\n",
    "    # Calcula o Score de Cosine Similarity para usar no NDCG\n",
    "    titles_score = cosine_similarity(query_title, [title])[0]    \n",
    "    description_score = cosine_similarity(query_description, [description])[0]\n",
    "    location_score = cosine_similarity(query_location, [location])[0]\n",
    "    \n",
    "    # Estamos considerando que os campos possuem o mesmo peso.\n",
    "    # Caso queira considerar pesos diferentes ser치 necess치rio aplicar os mesmo pesos \n",
    "    # posteriormente na API\n",
    "    dataset.at[i, \"model_score\"] = ((titles_score + description_score + location_score) / 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ff8b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"artificial_score\"] = dataset[\"artificial_score\"].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245410ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndcg_dataset = dataset[[\"vacancy_id\",\"artificial_score\", \"model_score\"]]\n",
    "ndcg_dataset = ndcg_dataset.groupby(\"vacancy_id\").agg(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f005afd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndcg_dataset.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7e125b",
   "metadata": {},
   "source": [
    "# Trunca as listas de score para apenas 5 itens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c417fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndcg_dataset[\"artificial_score\"] = ndcg_dataset[\"artificial_score\"].apply(lambda x: x[:5])\n",
    "ndcg_dataset[\"model_score\"] = ndcg_dataset[\"model_score\"].apply(lambda x: x[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d80aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndcg_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35164541",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = ndcg_score(ndcg_dataset[\"artificial_score\"].to_list(), ndcg_dataset[\"model_score\"].to_list(), k=5)\n",
    "print(f\"NDCG@5: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a022d4",
   "metadata": {},
   "source": [
    "# Registra o resultado do NDCG no banco de dados para monitoramento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0265e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(f\"\"\"SELECT {score} AS score\"\"\").write.jdbc( \\\n",
    "    url=\"jdbc:mysql://localhost:3306/decision\", \\\n",
    "    table=\"ndcg_results\", \\\n",
    "    mode=\"append\", \\\n",
    "    properties={\"driver\":\"com.mysql.jdbc.Driver\", \"user\":\"decision\", \"password\":\"1234\"} \\\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
