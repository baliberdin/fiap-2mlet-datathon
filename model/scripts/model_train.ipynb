{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc96cc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "import pandas as pd\n",
    "from data_transform_utilities.text_parsers import  clean_str, extract_json, json_str_to_array, normalize_and_tokenize_text\n",
    "from data_transform_utilities.score import generate_score_from_status\n",
    "\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import FloatType\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "import json\n",
    "import requests\n",
    "import os\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "\n",
    "import mlflow\n",
    "from sentence_transformers import SentenceTransformer, InputExample, models, losses, evaluation\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import mlflow.pytorch\n",
    "import mlflow.sentence_transformers\n",
    "import mlflow.sentence_transformers\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b3df7b",
   "metadata": {},
   "source": [
    "## Define algumas variáveis de ambiente para poder rodar ROCm com placas de vídeo AMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6a9aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.environ[\"TORCH_DISTRIBUTED_DEBUG\"] = \"DETAIL\"\n",
    "os.environ[\"NCCL_P2P_DISABLE\"] = \"1\"\n",
    "os.environ[\"NCCL_SHM_DISABLE\"] = \"1\"\n",
    "os.environ[\"NCCL_DEBUG\"] = \"INFO\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52049c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.version.hip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c20798b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_conf = SparkConf()\n",
    "spark_conf.set(\"spark.cores\", \"12\")\n",
    "spark_conf.set(\"spark.driver.cores\", \"12\")\n",
    "#spark_conf.set(\"spark.driver.memory\", \"16g\")\n",
    "spark_conf.set(\"spark.speculation\", False)\n",
    "spark_conf.set(\"spark.jars.packages\", \"com.mysql:mysql-connector-j:9.2.0\")\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder.master(\"local\") \\\n",
    "    .appName(\"Decision data overview\") \\\n",
    "    .config(conf=spark_conf) \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df6a420",
   "metadata": {},
   "source": [
    "# Extrai os dados do banco Relacional para Treinamento do Modelo e Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f058833a",
   "metadata": {},
   "source": [
    "## Cria conexão com banco relacionsl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801596cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(\"mysql+pymysql://decision:1234@localhost/decision?charset=utf8\")\n",
    "days_to_read = 1800"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5588a1",
   "metadata": {},
   "source": [
    "# Registra UDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e666f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.udf.register(\"clean_str\", clean_str)\n",
    "spark.udf.register(\"generate_score_from_status\", generate_score_from_status, FloatType())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a9f95b",
   "metadata": {},
   "source": [
    "## Carrega os dados de vagas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391e7aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.read.jdbc(\n",
    "    url=\"jdbc:mysql://decision:1234@localhost:3306/decision?charset=utf8\",\n",
    "    table=f\"(SELECT * FROM vacancies WHERE requested_date > DATE_ADD(current_date(), INTERVAL -{days_to_read} DAY)) AS t\",\n",
    "    properties={\"driver\": \"com.mysql.cj.jdbc.Driver\"}\n",
    ").createOrReplaceTempView(\"vacancies\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef9ab03",
   "metadata": {},
   "source": [
    "# Carrega os dados de candidatos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ddfa9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.read.jdbc(\n",
    "    url=\"jdbc:mysql://decision:1234@localhost:3306/decision?charset=utf8\",\n",
    "    table=f\"(SELECT * FROM applicants WHERE created_at > DATE_ADD(current_date(), INTERVAL -{days_to_read} DAY)) AS t\",\n",
    "    properties={\"driver\": \"com.mysql.cj.jdbc.Driver\"}\n",
    ").createOrReplaceTempView(\"applicants\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e011f44c",
   "metadata": {},
   "source": [
    "## Carrega os dados de candidatos que se canditaram a uma vaga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a57897",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.read.jdbc(\n",
    "    url=\"jdbc:mysql://decision:1234@localhost:3306/decision?charset=utf8\",\n",
    "    table=f\"(SELECT * FROM vacancies_applicants WHERE application_date > DATE_ADD(current_date(), INTERVAL -{days_to_read} DAY)) AS t\",\n",
    "    properties={\"driver\": \"com.mysql.cj.jdbc.Driver\"}\n",
    ").createOrReplaceTempView(\"vacancies_applicants\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8aae22",
   "metadata": {},
   "source": [
    "## Extrai apenas os campos textuais mais significativos para os datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c49dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(f\"\"\"\n",
    "    SELECT\n",
    "        va.vacancy_id,\n",
    "        va.applicant_id,\n",
    "        LOWER(TRIM(clean_str(v.title))) as vacancy_title,\n",
    "        LOWER(COALESCE(v.country, '')) AS country,\n",
    "        LOWER(COALESCE(v.city, '')) AS city,\n",
    "        LOWER(COALESCE(v.state, '')) AS state,\n",
    "        LOWER(COALESCE(v.main_activities, '')) AS main_activities,\n",
    "        LOWER(COALESCE(v.behavioral_skills, '')) AS behavioral_skills,\n",
    "        LOWER(COALESCE(v.technical_and_behavioral_skills, '')) AS technical_and_behavioral_skills,\n",
    "        LOWER(COALESCE(a.location, '')) AS applicant_location,\n",
    "        LOWER(COALESCE(a.professional_title, '')) AS professional_title,\n",
    "        LOWER(COALESCE(a.technical_knowledge, '')) AS technical_knowledge,\n",
    "        LOWER(COALESCE(a.cv_pt,'')) AS cv_pt,\n",
    "        LOWER(COALESCE(a.area_of_expertise,'')) AS area_of_expertise,\n",
    "        generate_score_from_status(status) AS artificial_score\n",
    "    FROM\n",
    "        vacancies_applicants va \n",
    "        LEFT JOIN vacancies v ON v.id = va.vacancy_id \n",
    "        LEFT JOIN applicants a ON a.id = va.applicant_id\n",
    "    WHERE\n",
    "        va.vacancy_id IN\n",
    "            (SELECT\n",
    "                va.vacancy_id\n",
    "            FROM\n",
    "                vacancies_applicants va\n",
    "            GROUP BY 1\n",
    "            HAVING COUNT(DISTINCT va.status) >= 5)          \n",
    "\"\"\").createOrReplaceTempView(\"tmp_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156521ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = spark.sql(f\"\"\"\n",
    "    SELECT\n",
    "        *\n",
    "    FROM\n",
    "        (SELECT\n",
    "            vacancy_id,\n",
    "            CLEAN_STR(\n",
    "                if(main_activities = technical_and_behavioral_skills,\n",
    "                main_activities\n",
    "                ,\n",
    "                CONCAT(\n",
    "                    main_activities, '\\n', \n",
    "                    technical_and_behavioral_skills, '\\n',\n",
    "                    behavioral_skills\n",
    "                )\n",
    "            )) AS vacancy_description,\n",
    "            \n",
    "            vacancy_title,\n",
    "            CONCAT( state, ', ', city) AS vacancy_location,\n",
    "            \n",
    "            applicant_id,\n",
    "            CLEAN_STR(professional_title) AS applicant_title,\n",
    "            TRIM(CLEAN_STR(CONCAT(technical_knowledge, '\\n', cv_pt, '\\n', area_of_expertise))) AS applicant_description,\n",
    "            applicant_location,\n",
    "            artificial_score\n",
    "        FROM \n",
    "            tmp_data v\n",
    "        ) AS t\n",
    "    WHERE\n",
    "        LENGTH(vacancy_title) > 0\n",
    "        AND LENGTH(vacancy_description) > 150\n",
    "        AND LENGTH(vacancy_location) > 0\n",
    "        AND LENGTH(applicant_title) > 0\n",
    "        AND LENGTH(applicant_description) > 150\n",
    "        AND LENGTH(applicant_location) > 0\n",
    "        AND artificial_score IS NOT NULL\n",
    "    \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3818fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train_df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64351de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a43b76",
   "metadata": {},
   "source": [
    "# Formatando os dados para o SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6801de8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifica se os rótulos estão normalizados\n",
    "assert df['artificial_score'].between(0.0, 1.0).all(), \"Coluna 'afinidade' deve estar entre 0 e 1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c79083",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_examples = [\n",
    "    InputExample(texts=[ [row.vacancy_title, row.vacancy_description, row.vacancy_location] , [row.applicant_title, row.applicant_description, row.applicant_location] ], label=float(row.artificial_score))\n",
    "    for row in df.itertuples()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4330304",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples, test_samples = train_test_split(input_examples, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb6f7b2",
   "metadata": {},
   "source": [
    "# Definição do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9659ca96",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"neuralmind/bert-base-portuguese-cased\"\n",
    "#model_name = \"google-bert/bert-base-uncased\"\n",
    "#model_name = \"google-bert/bert-base-multilingual-cased\"\n",
    "#model_name = \"google-bert/bert-base-multilingual-uncased\"\n",
    "bert = models.Transformer(model_name)\n",
    "\n",
    "pooling = models.Pooling(\n",
    "    bert.get_word_embedding_dimension(),\n",
    "    pooling_mode=\"mean\"\n",
    ")\n",
    "\n",
    "model = SentenceTransformer(modules=[bert, pooling])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ca87ba",
   "metadata": {},
   "source": [
    "# Hiperparâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fcb2e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 30\n",
    "epochs = 4\n",
    "steps_per_epoch = int(1000 / batch_size)\n",
    "total_steps = steps_per_epoch * epochs\n",
    "warmup_steps = int(total_steps * 0.1)\n",
    "evaluation_steps = int(total_steps * 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea288d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_samples, shuffle=True, batch_size=batch_size)\n",
    "train_loss = losses.CosineSimilarityLoss(model)\n",
    "output_dir = \"./trained_model\"\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b71fd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'applicant_job_similarity'\n",
    "MLFLOW_TRACKING_URI = 'http://localhost:5000'\n",
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "mlflow.set_experiment('Applicant Job Similarity')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d356a331",
   "metadata": {},
   "source": [
    "# Execução do Treino e publicação do Modelo no MLFlowServer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7513d1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlflow_logging_callback(score, epoch, steps):\n",
    "   mlflow.log_metric(\"val_score\", score, step=int(epoch))\n",
    "\n",
    "\n",
    "evaluator = evaluation.EmbeddingSimilarityEvaluator.from_input_examples(test_samples, name=\"val\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "   model.fit(\n",
    "      train_objectives=[(train_dataloader, train_loss)],\n",
    "      epochs=epochs,\n",
    "      steps_per_epoch=steps_per_epoch,\n",
    "      warmup_steps=warmup_steps,\n",
    "      output_path=output_dir,\n",
    "      show_progress_bar=True,\n",
    "      evaluator=evaluator,\n",
    "      callback=mlflow_logging_callback,\n",
    "      evaluation_steps=steps_per_epoch,\n",
    "   )\n",
    "\n",
    "   metrics = evaluator(model, output_path=None, epoch=-1, steps=-1)\n",
    "   for name, value in metrics.items():\n",
    "      mlflow.log_metric(name, value)\n",
    "    \n",
    "   mlflow.log_param(\"base_model\", model_name)\n",
    "   mlflow.log_param(\"loss\", \"CosineSimilarityLoss\")\n",
    "                                      \n",
    "   mlflow.sentence_transformers.log_model(model, \"trained_model\", registered_model_name=MODEL_NAME)\n",
    "   mlflow.end_run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
